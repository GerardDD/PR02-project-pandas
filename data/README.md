![IronHack Logo](https://s3-eu-west-1.amazonaws.com/ih-materials/uploads/upload_d5c5793015fec3be28a63c4fa3dd4d55.png)

# Guided Project: Demonstration of Data Cleaning and Manipulation with Pandas

## Workflow

 1) Imported csv with pandas.read_csv method, with encoding 'latin1'
 2) First look of the dataframe with head/describe
 3) Trimmed column names
 4) Check for duplicate registers with drop_duplicates
 5) Check for All-NaN registers with dropna, how='all'
 6) Dropping useless columns with drop
 7) Consolidating values applying lambda functions to specific columns
 8) Comparing similar columns and consolidating values in one of them
 9) Using regex to clean wrong URLs
 10) Cleaned some values with replace
 11) Changed order of the dataframe with set_index and sort_index
 12) Used regex and bag of word technique to extract shark species and injury types and consolidating values on their columns
 13) Simplifyed values on year column to make them more analysis-proof
 14) Dropped column with more than 50% of values == NaN
 15) Cleaned all the remaining NaN values with fillna method
 16) Generated csv with pandas.to_csv method
  

---

## Presentation

https://slides.com/gerarddomenechdomingo/project02


